---
templateKey: index-page
title: Architecting for the Edge
subtitle: >-
  Quadric is building the only end-to-end architecture optimized for realtime
  edge computing
images:
  - id: 1
    image: /img/full_bg3.jpg
  - id: 2
    image: /img/full_bg1.jpg
technology:
  benefits:
    content1: >-
      Our software makes it easy to work with parallel code, and we’re NOT
      requiring developers to learn anything new.
    content2: >-
      We’ve created a more open developer ecosystem, reducing duplication and
      enabling easier collaboration and faster development.
    content3: >-
      Our full-stack solution is designed for efficiency and realtime
      responsiveness, reducing both latency and power consumption.
    description: >-
      Tomorrow’s software will not look like today’s, which makes flexibility
      more important than ever. By enabling the fastest computation imaginable
      at lower power than ever, Quadric is ushering in a whole new world of
      possibilities for developers. The Quadric Processor is built to give
      developers newfound superpowers and get them to the future faster:
    heading1: Architected for ease
    heading2: Architected for collaboration
    heading3: Architected for performance
    image: /img/full_render-recovered-2-bazookatransparentfinal.png
  industries:
    description: >-
      Quadric’s edge processors can be incorporated into a wide range of
      products that require instantaneous processing of real-world data streams
      with minimal power and maximum speed. Industries Quadric is designed for
      include:
  overview:
    description: >-
      When every millisecond matters, edge processing is the realtime computing
      answer. Quadric’s full-stack system is designed to meet the powerful needs
      of next-level autonomous products, like self-driving cars and robots. We
      give developers superpowers to create the technology of tomorrow, today.
    image: /img/full_quadric-chip.png
    title: Making Realtime Real
about:
  overview:
    content: >-
      # Our Vision


      Quadric believes the road to an autonomous future must be completely
      re-architected. As the need for speed becomes more important than ever for
      millisecond decision-making in machines, data doesn’t have time to go
      round-trip to the cloud. Advanced edge computing is the answer, but
      requires a start-from-scratch approach.


      By combining high performance computing with the most sophisticated
      artificial intelligence, Quadric’s technology is helping to realize the
      promise of the future: where cars will finally commute safely for us,
      where industrial robots will complete critical tasks, where humans will
      communicate with machines like never before.


      # Our Mission


      To empower developers with the tools needed to create tomorrow’s
      technology, today.
    image: /img/full_module-bg.jpg
  team:
    description: >-
      Co-founded by three experienced technologist entrepreneurs with multiple
      successful exits between them, Quadric’s team has both deep technical
      expertise as well as strong business acumen.
    members:
      - bio1: >-
          Veerbhan has founded three technology companies and has full stack
          expertise spanning from ASIC’s and Datacenters to consumer facing
          products. Along with his Quadric co-founders, Veerbhan co-founded 21,
          Inc (in 2013) with the goal of bringing high-performance
          supercomputers to the cryptocurrency space. Veerbhan served in various
          roles ranging from designing custom ASICs (3 chips in 18 months),
          developing web scale blockchain backends &amp; building consumer
          facing mobile apps and products. Prior to 21, Veerbhan co-founded
          Fabbrix, Inc (in 2005) which was acquired by PDF Solutions in 2007.
          Fabbrix was focused on tools and flows that enabled design for
          manufacturability of complex Integrated Circuits. Post acquisition,
          Veer led several initiatives at PDF Solutions including product
          roadmap, data analytics & technical marketing.
        bio2: >-
          Veer is responsible for designing a memorable journey for everyone
          involved with [quadric.io](http://quadric.io/) and building an amazing
          company. Always looking for breakthroughs in technology,
          relationships, recruiting & parenting.
        education: |-
          Ph.D, M.S ECE from Carnegie Mellon University 2005

          BS, ECE (2002) from Indian Institute of Tech, Kharagpur
        key: VK
        linkedin: 'https://www.linkedin.com/in/veerbhan/'
        name: Veerbhan Kheterpal
        photo: /img/client_qdc190319-525.jpg
        pinToTop: true
        position: Cofounder & CEO
        thumbPhoto: /img/client_qdc190319-413.jpg
      - bio1: >-
          Prior to Quadric, Nigel was the Chief Architect & Co-founder at 21,
          Inc. where he designed and built-out all of the technology the company
          used to mine bitcoin: ASICs, HPC systems as well as much of the
          software that operated those systems. Nigel developed 3 ASICs in 18
          months (2 x 22nm, 1 x 40nm), and was the primary technical interaction
          point with Intel Custom Foundry. He was previously in a Research &amp;
          Development role spanning semiconductor test structure development
          &amp; software at PDF Solutions and also worked at Intel on ASIC flows
          for a block of high-performance microprocessor as well as automation
          for timing flows.
        bio2: >-
          Nigel is responsible for quadric's technology stack, spanning software
          to silicon. Nigel's interests outside of technology include running
          (these days, primarily after his twin toddlers), powerlifting,
          photography and travel.
        education: |-
          PhD, Electrical Engineering from MIT

          MS, Electrical Engineering from MIT

          BS, Computer Engineering from UC, Irvine
        key: ND
        linkedin: 'https://www.linkedin.com/in/nigeldrego/'
        name: Nigel Drego
        photo: /img/client_qdc190319-1263-2.jpg
        pinToTop: true
        position: Cofounder & CTO
        thumbPhoto: /img/client_qdc190319-1279-2.jpg
      - bio1: >-
          Prior to Quadric, Daniel co-founded 21, Inc in 2013 with the goal of
          bringing high-performance compute to the cryptocurrency space. On the
          chip-side, Daniel handled microarchitecture of the cryptocurrency
          algorithms and oversaw the physical implementation and manufacturing
          of 21’s first chips. Daniel led the design and deployment of 21’s
          bitcoin mining systems into datacenters. During 21’s push to empower
          the developer with Bitcoin, Daniel was responsible for design,
          development, channel distribution and support of the 21 Bitcoin
          Computer. He led business development efforts for licensing 21’s
          Bitcoin-related IP. Prior to 21, Daniel was a Senior R&D Engineer at
          PDF Solutions working on silicon big data collection, analytics and
          presentation methods.
        bio2: >-
          Daniel leads product at Quadric. Daniel’s interests include robotics,
          3d printing, and computing. Daniel believes that the confluence of
          these things will lead to better products, a safer world and more free
          time to do the things we enjoy.
        education: |-
          MS EECE University of Florida 2006

          BS EECE University of Florida 2005
        key: DF
        linkedin: 'https://www.linkedin.com/in/dfiru/'
        name: Daniel Firu
        photo: /img/client_qdc190319-946-2.jpg
        pinToTop: true
        position: Cofounder & CPO
        thumbPhoto: /img/client_qdc190319-926-2.jpg
      - key: AS
        name: Aman Sikka
        pinToTop: false
        thumbPhoto: /img/client_qdc190319-1019-2.jpg
      - key: SY
        name: Shayan Yassami
        pinToTop: false
        thumbPhoto: /img/client_qdc190319-685.jpg
      - key: PL
        name: Pablo Levi
        pinToTop: false
        thumbPhoto: /img/client_qdc190319-1827.jpg
      - key: AK
        name: Anand Kannan
        pinToTop: false
        thumbPhoto: /img/client_qdc190319-44.jpg
      - key: JW
        name: Jack Wang
        pinToTop: false
        thumbPhoto: /img/client_qdc190319-310.jpg
      - key: MP
        name: Marian Petre
        pinToTop: false
        thumbPhoto: /img/client_qdc190712-235-2.jpg
      - key: BW
        name: Brian Wilcox
        pinToTop: false
        thumbPhoto: /img/client_qdc190712-368-2.jpg
      - key: RG
        name: Rich Goldstein
        pinToTop: false
        thumbPhoto: /img/client_qdc190319-1746.jpg
      - key: TN
        name: Thomas Ng
        pinToTop: false
        thumbPhoto: /img/client_qdc190712-755-2.jpg
      - key: MR
        name: Mirinalini Ravichandran
        pinToTop: false
        thumbPhoto: /img/client_qdc190319-1342-2.jpg
      - key: PA
        name: Prashant Arora
        pinToTop: false
        thumbPhoto: /img/client_qdc190712-559__1_.jpg
      - key: BP
        name: Brandom Powell
        pinToTop: false
        thumbPhoto: /img/client_qdc190712-221-2.jpg
      - key: SQ
        name: Sammie Qadir
        pinToTop: false
        thumbPhoto: /img/client_qdc190712-19-2.jpg
investors:
  - image: /img/client_sv_angel_logo_vector.png
    lg:
      height: 12
      width: 12
      x: 0
      'y': 0
    md:
      height: 15
      width: 15
      x: 0
      'y': 0
    name: SVAngel
    sm:
      height: 10
      width: 10
      x: 0
      'y': 0
    website: 'https://svangel.com/'
    xs:
      height: 10
      width: 10
      x: 0
      'y': 0
  - image: /img/client_denso.png
    lg:
      height: 24
      width: 24
      x: 12
      'y': 0
    md:
      height: 30
      width: 30
      x: 15
      'y': 0
    name: Denso
    sm:
      height: 20
      width: 20
      x: 10
      'y': 0
    website: 'https://www.denso.com/global/en'
    xs:
      height: 20
      width: 20
      x: 10
      'y': 0
  - image: /img/client_cotacapital.png
    lg:
      height: 12
      width: 12
      x: 36
      'y': 0
    md:
      height: 15
      width: 15
      x: 45
      'y': 0
    name: COTACAPITAL
    sm:
      height: 10
      width: 10
      x: 0
      'y': 10
    website: 'http://cotacapital.com/'
    xs:
      height: 10
      width: 10
      x: 0
      'y': 10
  - image: /img/client_trucks_logo.png
    lg:
      height: 12
      width: 12
      x: 48
      'y': 0
    md:
      height: 15
      width: 15
      x: 0
      'y': 15
    name: TRUCKS
    sm:
      height: 10
      width: 10
      x: 0
      'y': 20
    website: 'http://www.trucks.vc/'
    xs:
      height: 10
      width: 10
      x: 0
      'y': 20
  - image: /img/client_uncork_full_mark_2colorc_red.png
    lg:
      height: 12
      width: 12
      x: 0
      'y': 12
    md:
      height: 15
      width: 15
      x: 45
      'y': 15
    name: UNICORK
    sm:
      height: 10
      width: 10
      x: 10
      'y': 20
    website: 'https://uncorkcapital.com/'
    xs:
      height: 10
      width: 10
      x: 10
      'y': 20
  - image: /img/client_leawood_vc_logo.png
    lg:
      height: 12
      width: 12
      x: 0
      'y': 24
    md:
      height: 15
      width: 15
      x: 30
      'y': 30
    name: LEAWOOD
    sm:
      height: 10
      width: 10
      x: 20
      'y': 20
    website: 'http://www.leawoodvc.com/'
    xs:
      height: 10
      width: 10
      x: 20
      'y': 20
  - image: /img/client_pear-logo_gradient_4c.png
    lg:
      height: 24
      width: 24
      x: 36
      'y': 12
    md:
      height: 30
      width: 30
      x: 0
      'y': 30
    name: PEAR
    sm:
      height: 20
      width: 20
      x: 0
      'y': 30
    website: 'https://www.pear.vc/'
    xs:
      height: 20
      width: 20
      x: 0
      'y': 30
joinOurTeam:
  description: >-
    Our team is as thoughtfully architected as our product; in fact, the two go
    hand-in-hand. We are looking for technical ninjas, who are ready for the
    adventure of a lifetime.  What do we mean by ninjas? We mean people with
    deep domain expertise who are driven by the desire to do something BIG in
    the company of good people. Our team is built upon mutual respect for what
    everyone brings to our end-to-end system. Without each part, there would be
    no whole. As such, our team is collaborative and focused. [See
    Jobs](https://jobs.lever.co/quadric)
  ourGoal: >-
    For employees to look back on this chapter of building the company with
    amazing memories -- remembering it as a time that was challenging and
    exciting as we worked together to build something extraordinary.
  photos:
    - image: /img/full_qdc190319-2374.jpg
      lg:
        height: 12
        width: 12
        x: 0
        'y': 0
      md:
        height: 15
        width: 15
        x: 0
        'y': 0
      sm:
        height: 15
        width: 15
        x: 0
        'y': 0
      xs:
        height: 10
        width: 10
        x: 0
        'y': 0
    - image: /img/full_qdc190319-1957.jpg
      lg:
        height: 12
        width: 12
        x: 12
        'y': 0
      md:
        height: 15
        width: 15
        x: 15
        'y': 0
      sm:
        height: 15
        width: 15
        x: 15
        'y': 0
      xs:
        height: 10
        width: 10
        x: 10
        'y': 0
    - image: /img/full_img_0563.jpg
      lg:
        height: 24
        width: 24
        x: 24
        'y': 0
      md:
        height: 30
        width: 30
        x: 30
        'y': 0
      sm:
        height: 15
        width: 15
        x: 0
        'y': 15
      xs:
        height: 10
        width: 10
        x: 20
        'y': 0
    - image: /img/full_img_20190128_130715.jpg
      lg:
        height: 12
        width: 12
        x: 48
        'y': 0
      md:
        height: 15
        width: 15
        x: 0
        'y': 15
      sm:
        height: 15
        width: 15
        x: 15
        'y': 15
      xs:
        height: 10
        width: 10
        x: 0
        'y': 10
    - image: /img/full_57040455657__0987513c-da9e-4b8a-be1b-d48b3551e0d9.jpg
      lg:
        height: 12
        width: 12
        x: 48
        'y': 12
      md:
        height: 15
        width: 15
        x: 30
        'y': 30
      sm:
        height: 15
        width: 15
        x: 0
        'y': 30
      xs:
        height: 10
        width: 10
        x: 10
        'y': 10
    - image: /img/full_qdc190319-2411.jpg
      lg:
        height: 24
        width: 24
        x: 0
        'y': 12
      md:
        height: 30
        width: 30
        x: 0
        'y': 30
      sm:
        height: 15
        width: 15
        x: 15
        'y': 30
      xs:
        height: 10
        width: 10
        x: 20
        'y': 10
    - image: /img/full_qdc190319-1657.jpg
      lg:
        height: 24
        width: 24
        x: 24
        'y': 24
      md:
        height: 30
        width: 30
        x: 30
        'y': 45
      sm:
        height: 15
        width: 15
        x: 0
        'y': 45
      xs:
        height: 10
        width: 10
        x: 0
        'y': 20
    - image: /img/full_qdc190319-1604-2.jpg
      lg:
        height: 12
        width: 12
        x: 48
        'y': 24
      md:
        height: 15
        width: 15
        x: 45
        'y': 30
      sm:
        height: 15
        width: 15
        x: 15
        'y': 45
      xs:
        height: 10
        width: 10
        x: 10
        'y': 20
    - image: /img/full_qdc190319-2002.jpg
      lg:
        height: 24
        width: 24
        x: 0
        'y': 36
      md:
        height: 30
        width: 30
        x: 0
        'y': 60
      sm:
        height: 15
        width: 15
        x: 0
        'y': 60
      xs:
        height: 10
        width: 10
        x: 20
        'y': 20
    - image: /img/full_qdc190319-1975.jpg
      lg:
        height: 24
        width: 24
        x: 24
        'y': 48
      md:
        height: 30
        width: 30
        x: 30
        'y': 75
      sm:
        height: 15
        width: 15
        x: 15
        'y': 60
      xs:
        height: 10
        width: 10
        x: 0
        'y': 30
    - image: /img/full_qdc190319-2208.jpg
      lg:
        height: 24
        width: 24
        x: 0
        'y': 60
      md:
        height: 30
        width: 30
        x: 0
        'y': 90
      sm:
        height: 15
        width: 15
        x: 0
        'y': 75
      xs:
        height: 10
        width: 10
        x: 10
        'y': 30
    - image: /img/full_qdc190319-1639.jpg
      lg:
        height: 24
        width: 24
        x: 24
        'y': 72
      md:
        height: 30
        width: 30
        x: 30
        'y': 105
      sm:
        height: 15
        width: 15
        x: 15
        'y': 75
      xs:
        height: 10
        width: 10
        x: 20
        'y': 30
  title: in search of ninjas
  whatWeExpect: 'Initiative, Collaboration, Completion'
  whatWeHave: 'Integrity, Humility, Happiness'
paperwork:
  - content: |-
      ![Logo](/img/client_preview_logo_black.png "Logo")

      # Edge Supercomputing

      #### April 2019

      Daniel Firu, Co-founder and CPO
    id: edge-supercomputing
    imageAlign: left
  - content: >-
      # Executive Summary


      The proliferation of cameras and sensors into autonomous devices, calls
      for solutions that improve computational power while consuming less
      energy. Cloud computing has revolutionized the way we store and process
      data, but several handicaps, such as performance and bandwidth, limit
      applications as decisions on the Edge must be made with minimal latency.
      As autonomy and robotics work their way into critical functions in
      society- such as driverless cars, medical technology, and logistics- the
      high latency, limited bandwidth, fragile security, and lack of offline
      access inherent in cloud-computing presents serious concerns. Machines are
      required to recognize and process a complex and growing class of stimuli
      and algorithms, and real-time, direct communication between sensors and
      decisions is needed. These new demands are leading the drive towards Edge
      Supercomputing, whereby applications demand that data acquisition and
      processing occur at the edge of the access network and closer to users.


      While advancements in edge supercomputing have increased in recent years,
      developers still lack a unified product architecture that offers
      reconfigurability, generality, and scalability. To bring the power and
      performance of server-class hardware to the resource-constrained edge,
      Quadric's team built the world's first and only purpose-built platform for
      low latency edge computing. Our Supercomputer enables the deployment of
      tomorrow's algorithms today, whereby developers can customize their code,
      then deploy them with popular libraries and frameworks such as OpenCV,
      Tensorflow, and C++. Reconfigurability and broad support for artificial
      intelligence, as well as high-performance computing, gives the developer
      freedom to push the algorithmic envelope without compromising performance.


      In this white paper, we introduce Quadric's technical platform and product
      vision, showcasing the unique software stack, a rundown of product
      offerings and practical applications, and the technology blueprint that
      differentiates the Quadric Supercomputer. The reader will learn what to
      expect from the developer experience, how high-performance kernels can be
      incorporated with artificial intelligence models, and how kernels can be
      deployed on Quadric’s hardware products. We present Quadric’s product
      offering in terms of both software and hardware and show how the developer
      can minimize complexities inherent in both while simultaneously improving
      overall system performance.
    id: executive-summary
    imageAlign: left
  - content: >-
      # Introduction


      Recent advancements in software algorithms, compute performance and deep
      learning are revolutionizing human-machine interaction. When applying
      these developments to transportation, an autonomous vehicle can deliver
      people and goods safely and efficiently. In drone applications, safety
      inspections of remote pipelines and infrastructure assets can be
      undertaken without risks to humans. In industrial applications, developers
      can achieve greater levels of efficiency, precision, and scalability of
      manufacturing processes. When applied to consumer products, we can unlock
      long-promised automation, freeing up time to do more of the things we
      enjoy.  


      Because machine intelligence on the Edge relies on various sensors
      embedded in devices making real-time decisions, the computational power
      and low-latency required are greater than that which current data
      processing infrastructure (i.e., the cloud) is equipped to handle on a
      massive scale. These requirements create a shift in how and where data is
      processed. Data centers are moving portions of their computing closer to
      the devices receiving and sending data, and more users of AI enabled
      devices are preferring to process data on-site rather than in the cloud.
      Because data is stored locally rather than sent off, it enhances some
      aspects of security, particularly concerning privacy. The edge-computing
      space is opening up new avenues for innovation in modern computing, where
      the demand for high performance, low latency, energy efficient products
      has never been greater. 


      Despite progress in many areas, developers deploying cutting edge
      algorithms on the Edge remain resource constrained. Limitations define
      available edge-tailored product architecture for both hardware and
      software, and thus the true potential of machine intelligence to improve
      tasks and processes has not been achieved. AI and High-Performance
      workloads are tailored, by developers, for target hardware and not the
      other way around. Hardware should be purpose-built for these workloads.
      Developers seeking to orchestrate algorithms for new and novel challenges
      require room for experimentation and innovation. Available edge computing
      products tailored for innovator may allow for design flexibility, but lack
      the processing power to turn ideas into market-viable applications that
      can be put to use on a large scale.  


      On the other hand, products offering high-performance computing lack
      programming flexibility. So, as developers try to match more focused
      algorithms to a narrow product-defined roadmap, they find their efforts
      bottlenecked. Being developers ourselves, we met all of these challenges.
      So, we founded Quadric to build a product that brings server-class
      performance to the edge.
    id: introduction
  - content: >-
      #### The Problem: Heterogeneous Compute


      Developers deploy today’s leading autonomy algorithms on custom-built
      heterogenous hardware, where discrete components such as Digital Signal
      Processors, Field Programmable Gate Arrays, Graphics Processing Units, and
      General Purpose Processors share access to memory or DMA provisions and
      take turns processing stack components to meet software demands. To
      accommodate evolving software sophistication, the complexity of hardware
      must increase accordingly. In turn, because each hardware component in the
      heterogeneous compute stack has its unique software framework and
      programming models, software systems become even more complex, and
      hardware-specific constraints hinder the developer. 


      ![introduction-image](/img/client_high_level_schematic_-_heterogeneous_compute_2__1_.svg
      "introduction-image")


      _Figure 1: Heterogeneous computing systems contain various components that
      share access to memory or DMA provisions and take turns processing parts
      of the software stack._


      _Each of these processors occupies their own space in the market, and the
      shifting demand of applications determines the suitability of one over the
      other. For example, while various workloads in image processing have
      advanced to new and novel neural network techniques, many parts of the
      sense, prediction, decision loop still rely heavily on rule-based
      components. Because neural networks and high performance compute need to
      co-exist, the result is exponential system-level complexity. Path planning
      workloads may run on the Host CPU itself while forward-inferencing of
      artificial intelligence workloads run on a purpose-built AI accelerator.
      FPGA's, reprogrammable and designed for generality, offer flexibility for
      developers but come with an increase in hardware complexity. They are not
      software programmable, and hardware reconfigurability requires a team of
      specialized FPGA experts. GPU's are a standard choice for many AI
      applications because the need for parallelizable compute with a good
      reprogrammable software model is so pronounced. They offer high per-pin
      bandwidth but are memory constrained and good throughput. CPUs offer high
      single-threaded performance but lack the parallel architecture to
      accelerate modern workloads. The programming models and frameworks for
      each of the discrete processors can be vastly different. When optimizing
      each piece of a full-stack sense and control loop with its optimized
      hardware, the system-level orchestration software makes integration even
      more complicated. Scheduling which task is run when and on which hardware
      while maintaining throughput at each component becomes as complex as
      solving the actual product problem at hand. When characterizing the entire
      stack holistically, system level scheduling and memory domain marshaling
      consume a significant amount of total system resources and power. Such
      full-stack sensor-based edge machine intelligence applications demand a
      new architecture to enable the entire workload to be accelerated in a
      single latency, power, and performance-based architecture._ 


      _In all cases, the more programming flexibility and general purpose
      oriented the processor means compromises on performance, cost, and energy
      use. The need for performance leads to ASIC's, which are specialized
      processors designed for more specific functions. These can be
      client-specific or general but still oriented towards a single sector, or
      algorithm. The specificity of the application allows for a more targeted
      design, that cannot change to take into account innovation in algorithms,
      offers high performance. However, when taking into account system-level
      performance, simply replacing a single piece of a heterogeneous stack with
      a more performant one, does not always yield a large improvement for
      overall workloads._  


      _The solution demands a new processor architecture be built from the
      ground up. By considering all the products and applications that will be
      run from the top-down, Quadric has built an Edge optimized processor that
      provides the developer uncompromising performance for power constrained
      applications._
    id: heter-compute
    imageAlign: center
  - content: >-
      With this in mind, Quadric’s team set out to develop a single, unified
      processor architecture where developers have the power to write and unify
      all parallelizable algorithms onto a latency-optimized processor. Unified
      Compute gives the developer power to accelerate works onto a single
      cohesive software approach, without the need for complex hardware
      integration, varied software languages, and frameworks. To address the
      power and latency challenges at the edge, we designed a novel processor
      architecture that is flexible enough to handle all workloads of complex
      heterogeneous systems, without sacrificing performance. Quadric's
      Processor blends the best of current processing methods, offering ASIC
      level performance, the flexibility of an FPGA, the graphics processing
      power of a GPU, with the ease of use of a standard x86 processor. It’s the
      perfect balance between programmability and performance. 


      ![Unified Compute](/img/client_high_level_schematic_-_unified_compute.svg
      "Unified Compute")


      _Figure 2: The Quadric Processor replaces FPGA, GPU, and AI Accelerator
      hardware components. All software workloads previously running on those
      hardware components now run on a single latency, performance and power
      optimized processor architecture._


      ![Quadric Super
      Computer](/img/client_high_level_schematic_-_supercomputer.svg "Quadric
      Super Computer")


      _Figure 3: Ultimately, the Quadric Supercomputer execute all workloads,
      including those performed on the Host CPU itself._


      _In the following sections, we will describe the software ecosystem that
      is supported by Quadric Hardware products. We will also describe all forms
      of Quadric’s hardware products. First, the Quadric Supercomputer, a
      purpose-built latency-optimized system with full out-of-the-box support
      for eight cameras. Customers can integrate the Quadric Processor, the
      processor at the heart of Quadric’s Supercomputer into their hardware
      platforms. The Quadric IP, the purpose-built processor architecture at the
      heart of it all that can be integrated into customer’s SoC products.
      Quadric’s software ecosystem supports all of these hardware products.
      Write your code once, compile to any hardware target, and deploy
      algorithms at the edge._
    id: unified-compute
    imageAlign: center
  - content: '# Software Ecosystem'
    id: software-ecosystem
    imageAlign: center
  - content: >-
      #### Unified Software


      Algorithmic logic, rule-based approaches, and trained AI models will all
      co-exist in next-generation algorithms. Add to that the proliferation of
      cameras, LiDAR, and inertial sensors, and system complexity and bandwidth
      of incoming data only grows. As a result, we need more compute to
      understand the surrounding scene, localize within it, and plan a path
      through it. M sensors equal more compute. While the Quadric Processor
      addresses speed and power challenges, it does not simplify the software
      experience for the developer. To address the latter, Quadric developed a
      Software Framework that fuses these high-performance and graph-based
      development environments and their difficult-to-integrate components into
      a unified software experience.  


      A single architecture within an open software development kit (SDK)
      environment the unifies hardware and software integration efforts.
      Developers can combine and accelerate the development of applications
      requiring high performance for sense -> predict -> plan -> decide loops.
      Leveraging open source standards such as OpenCV, OpenVX, Tensorflow,
      Caffe, and standard C++ along with Halide and LLVM, developers can
      homogenize and simplify development efforts, more readily compiling code
      that would otherwise work on disparate heterogeneous components.
      Rule-based approaches lower elegantly onto Quadric’s platform where neural
      network approaches intertwine with standard algorithmic automata.
      Quadric’s hardware products accelerate all of these algorithms in a single
      latency-optimized compute fabric. The resulting product is ideal for
      deployments in power-constrained applications edge applications. 


      Most importantly, our SDK allows for programming flexibility. Software
      algorithms and best practices are in constant flux. The best-in-class
      algorithms of today may not look the same tomorrow. Unfortunately, current
      edge-tailored processors do not generally support easy customization of
      algorithms. Developers with increasingly complex algorithms, ones often
      designed for applications of societal importance and urgency, are finding
      that existing software platforms only provided support for a narrow set of
      specialized deployments. Running only the algorithms that fit within the
      pre-programmed platform means less than optimal accuracy. Quadric’s
      Software Framework opens up new avenues for developers seeking to put
      their algorithms to work today.


      ![Unified
      Software](/img/client_high_level_schematic_-_software_diagram__2_.svg
      "Unified Software")


      Figure 4: The Quadric Supercomputer’s software ecosystem allows for the
      use of popular programming languages and frameworks. 


      To illustrate various workloads, three example workloads of increasing
      complexity will be presented. The first kernel demonstrates a basic
      computer vision computation: the image histogram. Something as simple as
      an image histogram is typically a standard library call. However, we use
      it as an example to display the ease of use of our Intermediate Language,
      expressed in c++. The second kernel describes support for a common deep
      neural network graph operation: RESNET50. As we import RESNET directly
      from its description in common graph frameworks, like Tensorflow, we
      compare the network’s performance with other common hardware. The third
      workload is not a single kernel, but an entire sense and decision loop.
      The workload showcases the end-to-end versatility of Quadric’s
      architecture. The workload contains high performance compute kernels such
      as A* search and graph-based neural network kernels such as RESNET50. Once
      compiled, the entire stack runs on Quadric’s edge computing architecture.
    id: unified-software
    imageAlign: center
  - content: >-
      Quadric’s software approach can improve the computing of a key component
      of computer vision: the image histogram. A graphical representation of the
      tonal content within a captured image, an image histogram is used to
      discern whether an image is overexposed or underexposed, as well as for
      thresholding. Thresholding is a technique for generating segmentation
      masks, which allows images to be represented in simpler components that
      make them easier to interpret and analyze. These qualities make the image
      histograms useful in many fields. While in camera pipelines, histograms
      can be utilized for automated camera exposure control. Doctors use them to
      enhance medical images, and driverless cars to better recognize objects.


      ![Unified Software](/img/client_annotation_2019-05-13_211019.png "Unified
      Software")


      Figure 5: In this image histogram of Quadric's founders, the x-axis
      represents varying levels of tonal content, and the y-axis represents the
      total number of pixels within that tonal bucket. “Dark” content is
      represented close to the 0 on the x-axis. While the “light” content is
      represented closer to 255 on the x-axis. Since this is a portait-style
      picture, most of the pixels are bright and reside in bins 150-200.


      ```c

      #define HISTO_BINS 256

      int result[HISTO_BINS];


      cv::mat img;


      // step through the image row-wise then col-wise

      for (int i = 0; i < img.rows; i++) {
        for (int j = 0; j < img.cols; j++) {
          // You can now access the pixel value with cv::Vec3b
          uint intensity;
          uint bin;

          // calculate the intensity of the pixel
          // calculateIntensity will take the total number of bins and the pixel data
          intensity = calculateIntensity(HISTO_BINS, img.at<cv::Vec3b>(i, j));

          // lookup which bin this intensity will fall into
          // lookupBin will take the total number of bins and the intensity itself
          bin = lookupBin(HISTO_BINS, intensity);

          // increment the bin itself
          result[bin]++;
        }
      }


      ```


      _Figure 6: An image histogram can be computed simply by iterating through
      each pixel and comparing its tonal value against the number of discrete
      bins. Once a match is found, the bin is incremented, and we can move on to
      the next pixel. Above, pseudocode for computing the histogram of an image
      on a single-threaded machine._


      _Classically, the parallelization of the image histogram computation is
      achieved by:_ 


      1. Subdividing the input image between execution threads 

      2. Processing each subdivided array and computing an image histogram for
      each

      3. Merging the subdivided image histograms into the final image histogram
      result 



      When utilizing parallelized compute elements such as GPGPUs to compute
      image histograms, the developer must pay careful attention to how data is
      accessed and stored and possess deep knowledge of the nuances of hardware
      such as the arrangement of processing elements into groups and how the
      groups access physical memory.  


      Quadric’s Supercomputer offers a simplified approach, whereby the
      developer can define their algorithm in a single-threaded way (as the
      pseudocode in Figure 6 indicates), and the parallelism will be inferred
      and executed on Quadric’s processing fabric. While the image histogram is
      a very basic example that most platforms have a highly optimized library
      call for, it demonstrates how the importance of data locality in computer
      vision is better supported by Quadric’s software approach.
    id: computer-vision-image-histograms
    imageAlign: center
  - content: >-
      #### Deep Neural Networks: RESNET 50


      The enhancements our software approach lend to computer vision applied to
      deep neural networks, which have been a subject of intense interest for
      researchers and AI companies in recent decades.  Deep neural networks
      (DNN) are algorithms characterized by multiple layers between input and
      output, whereby subsequent layers learn input from the previous layer.
      [Convolutional Neural
      Networks](https://en.wikipedia.org/wiki/Convolutional_neural_network)
      (CNN), a category of DNN, convert complex patterns into many, many small,
      simple patterns. They have been used extensively in classification tasks
      in image and video recognition, classification, and natural language
      processing.  


      The basic premise of a CNN is to convert data complexity into many-deep
      classifiers, or filters, that are simpler in dimensional complexity than
      the previous layer’s data. This approach leads to much less
      computationally complex networks than fully connected neural network
      approaches. 


      ![Deep neural networks resnet 50](/img/client_cnv.png "Deep neural
      networks resnet 50")


      _Figure 7:  converting input tensors into several-deep filters of less
      width and height than the original layer._


      By assembling CNN layers in clever ways, one can construct network
      architectures that can perform point-tasks as well or, in some cases,
      better than a human being. For example, in 2012 a neural network called
      [Alexnet](https://en.wikipedia.org/wiki/AlexNet) developed a novel neural
      network architecture that proved CNN-based architectures could someday
      exceed human classification in the now-famous ImageNet challenge. By 2015,
      researchers were proving classification results on the Imagenet challenge
      that [exceeded human error
      rates](https://en.wikipedia.org/wiki/ImageNet#cite_note-microsoft2015-22).
      One such advanced CNN network architecture, RESNET50 strikes a balance
      between total computational network complexity and error rate. 


      ![Deep neural networks resnet 50](/img/client_network.png "Deep neural
      networks resnet 50")


      _Figure 8:  an example of a CNN-based neural network architecture_


      RESNET uses the concept of [residual
      layers](https://arxiv.org/abs/1512.03385), or shortcuts, that are
      preserved for future computation to improve network accuracy while
      minimizing overall network complexity.


      ![Deep neural networks resnet 50](/img/client_res.png "Deep neural
      networks resnet 50")


      _Figure 9: a RESNET residual building block. Notice the layer at the input
      (TOP) is preserved and utilized in computing the final sum (BOTTOM)._


      By exploiting data locality within a receptive field and by placing memory
      next to processing elements, Quadric’s products can perform feed-forward
      neural network inference at high speed, low latency, and low power. For
      RESNET50, batch one latency is an important compute metric. It quantifies
      the total amount of time to compute a single RESNET50 computation end to
      end. Quadric processor is latency and power optimized to meet the demands
      of the edge. Figure 8 shows the batch one latency versus an [NVIDIA
      Xavier.](https://developer.nvidia.com/embedded/jetson-agx-xavier-dl-inference-benchmarks)
      Figure 9 shows the compute efficiency against the same product. With these
      performance and power metrics, Quadric’s processors are well suited for
      all low-power high-performance edge applications.


      ![Deep neural networks resnet
      50](/img/client_annotation_2019-05-13_225041.png "Deep neural networks
      resnet 50")


      _Figure 10: RESNET50 batch 1 latency of q1-64 Quadric Processor versus
      best-in-class edge processor for comparable power level_


      ![Deep neural networks resnet
      50](/img/client_annotation_2019-05-13_225057.png "Deep neural networks
      resnet 50")


      _Figure 11: RESNET50 Compute efficiency of q1-64 Quadric Processor versus
      best-in-class edge processor for comparable power level_


      While RESNET50 performance is an important benchmark, the application of
      Artificial Intelligence is an ever-evolving field. High-performance neural
      network acceleration at low latency is only one aspect of what software
      developers needs. More importantly, the developer requires the freedom to
      change and experiment with network architecture. The algorithms of
      tomorrow will not look like the algorithms of today, and in the domain of
      Artificial Intelligence, that change is happening faster than ever.
      Quadric has developed a scalable general-purpose parallel processing
      architecture that gives developers the freedom they need to develop and
      deploy the networks of tomorrow. 


      While artificial intelligence applications solve or improve many algorithm
      domains, general-purpose high-performance computing algorithms are
      required to be deployed alongside neural networks. In the next section, we
      will describe, at a high level, a full stack Sense -> Decision loop.
    id: deep-neural-networks-resnet-50
    imageAlign: center
  - content: >-
      #### Full Robot Application: Sense and Control


      Before a robot can make decisions and effectively navigate and operate in
      real-world scenarios, it must be able to read and act upon the environment
      in a way similar to humans. It must sense and perceive terrain and
      geography while recognizing stationary and in-motion objects. This process
      begins with multiple sensors designed to detect objects, measure the
      terrain, and provide the robot with a sense of its location. Software and
      algorithms then make decisions based on the data provided by the sensors
      and send directions back to the robot. The Quadric Supercomputer is
      capable of running all algorithms required to implement an entire sense
      and control loop within a robot. To sense the environment, we employ two
      cameras, an inertial measurement unit, and one LiDAR. 


      ![Full Robot](/img/client_high_level_schematic_-_splpd_loop.svg "Full
      Robot")


      _Figure 12: On-board sensors such as cameras and LiDAR capture data about
      the environment, the data from the various sensors is fused, and software
      and algorithms interpret this data to decide and interact safely within
      the environment._


      Most datasets for self-driving are proprietary,  the example provided by
      [AVS.auto](https://avs.auto/#/about) is used to explain, at a high level,
      various aspects of the Self Driving Car control loop and how they map to
      the Quadric Supercomputer. AVS is an open source visualization framework
      open-sourced by Uber. LiDAR, two cameras, and an inertial measurement unit
      are used to transduce the analog information surround the vehicle’s
      environment to a raw digital representation. The control outputs are
      steering wheel angle and throttle position (e.g., longitudinal and lateral
      control).


      A robot utilizes cameras to capture images, and high definition video
      streams of objects in the surrounding environment then make decisions
      based on its resulting interpretation of the perceived environment. It
      employs [LiDAR](https://en.wikipedia.org/wiki/Lidar) to determine the
      distance between objects and the robot by sending out approximately 100
      light pulses/three-tenths of a second, then measuring the differences in
      return times and wave-lengths to assemble a 3-D digital representation of
      the environment. It uses an Inertial Measurement Unit, or IMU, which
      consists of accelerometers and gyroscopes that measure orientation, speed,
      and gravitational forces. These metrics are reported back to the robot to
      key it into where it resides within its environment. It can then form
      productive paths and ultimately issue braking, acceleration, and steering
      angle control instructions.


      Algorithms close to sensors are typically used to condition and remove
      noise from input sensors. For example, the developer may run a histogram
      equalization to feedback exposure parameters to the camera. Color space
      conversion can be utilized to trivialize downstream computations, such as
      traffic lanes extraction or traffic sign detection. Speeds and positions
      of other objects can be pre-computed to inform downstream vector space
      annotation during localization. We may want to run a connected components
      kernel on the LiDAR data to infer which points belong to the same object.
      Again to make localization and prediction easier downstream.


      A robot’s cognitive function rests in its ability to predict and infer
      based on the data gathered from the sensors. Software that relies on
      high-performance interpret images, terrain, and self-location. In the case
      of driverless cars, the vehicle needs to know the difference between a
      stop sign and a pedestrian, between a minivan up ahead and a semi on the
      right, then make split-second decisions based on this knowledge. Neural
      networks have proven to be the defacto standard for classification of
      objects within the perceptive field of the robot. Classical algorithms
      such as optical flow and segmentation are still very useful alongside
      neural networks to augment their use to understand the robot’s environment
      with higher accuracy. Further, the way the neural networks behave can be
      reinforced with rule-based expert knowledge within a particular domain.


      The CNN matches objects in the real-time image captures and video streams
      with those it is trained to understand. To isolate different objects in an
      environment and bring them into better focus relative to the background.
      Similarly, segmentation takes a digital image and divides into simpler
      components so that it is easier to analyze.  Objects in an environment are
      a mix of stable and in motion, and because a robot is also in motion,
      optic flow is used to represent the motion of objects relative to the
      robot. Since their position and the view will change concerning the
      movement of the robot, both static and in-motion objects will be
      represented as vector fields. Because a photo is a 2-D representation of a
      3-D landscape, the camera will capture an image of an object from
      different angles. As the convolutional network is seeking correlation to
      match the captured image with stored images in the database, it needs to
      identify a key point whereby the image, even at an angle, can be matched
      with its appropriate counterpart in the database. All of these approaches
      help to prepare and unify the robot's environment so that they may plan
      and make a decision on which actions to take.


      ![Full Robot](/img/client_annotation_2019-05-13_220253.png "Full Robot")


      _Table 1: summary of algorithm benchmarks running on a single q1-64
      processor._


      ![Full Robot](/img/client_topdown.png "Full Robot")


      _Figure 13: A top-down view of the robot with detected and classified
      obstacles. The process of localization places the robot within its
      perceived environment._


      To arrive at their objective- both literally and figuratively- robots must
      know how to formulate and follow a path within an environment. Thus, they
      must have an understanding of their position within the frame of
      reference. A stereo camera, equipped with two or more lenses, can assemble
      captured images from a scene and translate them into a 3-D representation,
      essentially constructing a map of the environment. As the robot moves
      within the environment, and as the objects within the environment are also
      fluid, there is a need to constantly update the map as well as the
      location of the robot within it. This process is called Simultaneous
      Location and Mapping, or SLAM. 


      A robot navigating an urban environment, such as the one in the AVS demo,
      must predict and plan the best path based on all information garnered from
      previous steps. It has utilized all of the above approaches to sense the
      environment, classify objects within that environment and place itself
      within the surrounding environment accurately. Now it must decide what
      plan of action it will take and finally make a decision: speed up, or slow
      down; swerve around an obstacle or come to a complete stop. These choices
      are not easy ones to make. And ideally, they must be made instantaneous.
      Because as time is taken to make a decision, the environment truth that
      the robot has built up for itself is getting stale. Because of this,
      computer algorithms utilized to make decisions must generate as many
      possible futures predictions and decide which one is the best course of
      action with minimum latency. Dijkstra's shortest path first algorithm,
      developed in 1959, which calculates the shortest possible distance between
      two nodes, and A*- an extension of Dijkstra's algorithm- that assists in
      finding a path between two points, or nodes. These algorithms run natively
      on the Quadric Supercomputer and Quadric Processor. 


      ![Full Robot](/img/client_persp.png "Full Robot")


      _Figure 14: The green path represents the predicted path which the vehicle
      will attempt to take given what it knows. Path planning algorithms
      generate many paths and return the best path given what the robot knows
      about its environment._


      Path planning is hard and often single-thread limited and data-access
      intensive. Data patterns are random as opposed to the predictable data
      patterns that are present in graph-based algorithms such as feed-forward
      neural networks. These types of applications are where Quadric’s
      technology stands out. The Quadric Processor has an efficient mix of both
      dataflow paradigms and random access paradigms at the hardware level. This
      unique characteristic makes the Quadric Processor the first purpose-built
      architecture capable of executing a full stack sense and control loop,
      including path planning, for complex robots such as self-driving cars.
    id: full-robot-application-sense-and-control
    imageAlign: center
  - content: >-
      # Hardware Ecosystem


      Quadric’s hardware offering is threefold offering that will be staggered
      in time. The first product that we will offer is Quadric Supercomputer.
      The Quadric Supercomputer integrates four Quadric q1-32 processors.
      Secondly, we will be releasing the q1-64 processor on its own for system
      integrators to design into their own purpose-built edge computers. Lastly,
      Quadric will make the Quadric Processing Array available for SoC
      integration.
    id: hardware-ecosystem
    imageAlign: center
  - content: >-
      #### Quadric Supercomputer


      The Quadric Supercomputer is Quadric’s first single board computer product
      and the world’s first purpose-built supercomputer for autonomy and
      robotics applications. It supports standard input/output for 8 HD cameras,
      LiDAR, radar, and IMU, along with the computational horsepower to back it
      up. With low-latency being the primary design principle, a developer can
      minimize the total photon-to-decision loop time. This newly enabled
      control will enable safer, smarter, more reactive robots and autonomous
      vehicles.


      ![Quadric Supercomputer](/img/client_render-recoveredveer00.png "Quadric
      Supercomputer")


      Figure 15: The Quadric Supercomputer contains 4 Quadric Processors, each
      consisting of a q1-64 Quadric Compute Array, Quadric Core R52 ARM
      processors, and the necessary interface IP to communicate with high
      bandwidth sensors.
    id: quadric-supercomputer
    imageAlign: center
  - content: >-
      # Quadric Processor, Array, and Core


      Quadric’s underlying compute element structure, the Quadric Array, is a
      scalable compute fabric containing the q1-32 Quadric Array fabric.
      Depending on the market and application, the Quadric Array can scale to
      meet the demands of various uses on the Edge.


      ![Quadric Processor Array And Core](/img/client_core.png "Quadric
      Processor Array And Core")


      _Figure 16: At the heart of the Quadric Array is the Quadric Core
      (rendered above), a proprietary and purpose-built compute element that
      helps accelerate algorithms with heavy parallelism and data locality. A q8
      contains 64 Quadric Cores; a q64 contains 4096, etc._  


      All embodiments of the Quadric Compute Array are supported by Quadric’s
      Compiler and Software Ecosystem, as discussed in the previous section.
      Maintaining software support across all embodiments of hardware allows for
      the development of algorithms once and the deployment of the algorithms to
      various endpoints.  


      For example, a RESNET50 neural network can be implemented by the end user.
      Depending on the target Quadric Array product, the neural network will
      have varying levels of performance. The following table offers the reader
      examples of single batch latency and power for various Quadric Array
      sizes.


      ![Quadric Processor](/img/client_annotation_2019-05-13_220519.png "Quadric
      Processor")


      Table 2: INT8 performance The quadric array contains 4096, 1024, 256 or 64
      Quadric Cores, which can be scaled up to meet the demands of various uses
      on the edge, depending on the application. *q1-128 with HBM2 memory. 


      A chip utilizing the q1-64 Quadric Array is well suited for
      high-performance low-latency applications where responsiveness and total
      edge computing are the primary design parameters. The q1-32 Quadric Array
      is incorporated in Quadric’s first processor offering: the Quadric
      Processor. This IP will see a total of four placements within the Quadric
      Supercomputer. The q1-16 and q1-8 are well suited for incorporation into
      product-specific SOCs.
    id: quadric-processor-array-and-core
    imageAlign: center
  - content: >
      # Applications


      The applications for Quadric’s edge supercomputer are those that require
      ultra-low latency, high bandwidth, and energy efficiency. Similar to
      self-driving cars described above, several well-known technologies are
      seen as having the potential to transform society, but have yet to
      overcome computational barriers within the power and latency constrained
      environments inherent in the current platforms. 


      #### Transportation


      Current computing solutions available to self-driving auto manufacturers
      and users are primarily application-specific standard products (ASSPs),
      which are integrated circuit products designed for limited applications
      and sold to various users within that market segment. Production of ASSPs
      is an expensive and time-intensive process, but they provide high
      performance, low energy compute solution. The algorithms of ASSP’s are
      written for the end-user and built-in to the semiconductor device, meaning
      that though the product can be sold to multiple users, there is not a
      possibility for the user to program their tailor-made algorithms. As the
      world of AI and driverless cars is in rapid development, and best-practice
      algorithms in constant flux, the ability to create and modify algorithms
      with open source software programs gives the user flexibility to push the
      creative envelope. Quadric’s first product offering allows for powerful
      user experience, without increasing energy consumption.


      #### Mobile SoCs


      As mobile phone users increasingly utilize AI-backed applications such as
      voice assistance, intelligent imaging, and facial recognition, phone
      manufacturers will be looking to include AI processors in their SoC
      platforms. Recent research suggests that by 2022, three-quarters of
      smartphones produced will have onboard AI, or about 1.25 billion
      smartphones (compared with the 190 million that utilize AI today).
      Currently, smartphone AI processing relies on the cloud and various
      processing components within the phone itself. However, the latency
      inherent in these processing methods limits the applications. With the
      race on among smartphone manufacturers to develop the best mobile SoC’s
      for AI applications beyond the trivial, the demand for low latency, high
      compute solutions only possible via edge supercomputing will also
      increase.


      #### Camera Sensors


      While certain AI capable devices may have only one or two sensors, others-
      like self-driving cars as discussed above- have several. When one
      considers not just one car, but entire intersections and cities filled
      with commuters, it's evident that the total amount of sensors added to the
      network will be immense. One estimate predicts that by 2020, the number of
      devices in IoT will be 50 billion. Cameras, LiDAR and other sensors that
      need instant feedback will be less reliable as the number of sensors- and
      thus raw data- is sent to the cloud for processing. Some concerns, besides
      latency, include limited bandwidth and potential privacy violations. Edge
      supercomputing moves the processing onto the device itself, or nearer,
      reducing latency and increasing security. It solves the problem of
      unreliable internet connection so that that camera sensors can work
      continuously regardless of distance from cloud infrastructure.


      #### Smart Sensors


      As companies, consumers, and developers find further applications for AI,
      the types of sensors on the market will increase. These sensors will be
      designed for more specific end-users, and require precision and accuracy
      that can lead them to be considered “smart sensors.” With CNN's and deep
      learning networks, sensors will be more than just pre-programmed, but
      rather learners within their domains, and further, need to communicate
      with one another. Sensors in networks in communication with one another
      will only serve to improve accuracy and precision in the sending back of
      decisions. The increased use of multiple sensors all gathering different
      data simultaneously requires high compute, low latency. In military and
      surveillance applications, the demand for tight security is critical. In
      heterogeneous processing, each hardware component in the heterogeneous
      compute stack has its unique software framework and programming models,
      which creates software complexity and hardware constraints. Edge
      supercomputing provides lower latency, higher computer, lower energy
      consumption, and more security. Quadric’s SoC and software flexibility
      resolves the problems caused by the complex hardware/software interplay in
      typical heterogeneous computing systems. With “smart sensors” relying
      heavily on deep learning, the ability of programmers to write their
      software, and improve upon previous models, is a huge benefit.


      #### Robots in the Industry


      Industries in which robotics are being looked into to improve processes,
      increase efficiency and ease the work burden on humans include
      agriculture, healthcare, manufacturing, construction, quality control,
      military, and banking, among others. Automation in manufacturing processes
      already relies on robots to perform menial or dangerous tasks such as
      welding, handling of raw material, and packaging. The further integration
      of machine vision and deep learning is allowing for manufacturing robots
      to adapt to problems as they occur and respond quickly with a solution.
      The trend in the manufacturing industry is moving from product automation
      to “smart” automation, and this evolution is based on the collection and
      processing of data from the manufacturing process as it is occurring and
      being captured by sensors. For instance, an industrial arm may be
      augmented with a camera to improve assembly and testing. Robots and
      sensors in geographically dispersed points will be able to share real-time
      information and improve processes for a company not just in a single
      factory, but at every step of the supply chain. The low latency and
      security necessary for these robotic applications will require on-site IT
      infrastructure. Edge computing brings data processing on-site, allowing
      for a host of robotics applications that can improve efficiency in several
      industries and processes. Quadric’s flexible software approach will allow
      developers to match the algorithms to idiosyncratic industrial processing
      blueprints. 


      #### Augmented and Virtual Reality


      Immersive systems that provide users with computer modified and computer
      generated experiences are one such arena. Augmented Reality (AR), in which
      digital renderings are imposed over a real-world environment, and Virtual
      Reality (VR), where the environment in which the user interacts is
      simulated in 3-D- both require real-time computing of graphics, sensors,
      and user inputs for the experience to be fluid and believable. If the user
      senses a delay in input-feedback, the human brain detects the artifice and
      the experience fails. While the general public is most familiar with AR/VR
      headsets for gaming experiences, uptake by industries such as military,
      healthcare, retail, mobile phones, and entertainment could create a
      multi-billion dollar industry in the coming decade. For that to happen,
      there needs to exist a computing architecture to support visual displays
      of 100 - 120 frames per second without intensive battery drain and the
      need to be tethered to a powerful PC station. With the low latency promise
      of edge super-computing, the potential for untethered mobile AR/VR gets
      closer to reality, and with Quadric’s open software feature, a developer
      or company with a very specific AR/VR application can experiment with and
      deploy algorithms tailored to their unique objective.


      To demonstrate this further, consider the possibilities for AR in
      healthcare. A nurse taking blood could superimpose a digital map of the
      veins over the patient, improving accuracy, or a surgeon could view
      radiology images overtop of the patient he is about to remove a brain
      tumor from, identifying in real time the best point of incision. Consider
      also the split-second accuracy that would be required as the surgeon moves
      about the patient and the superimposed radiology image needs to be
      continuously fitted to the patient in the real world. Computing latency
      must be ultra-low, meaning the processors need to be on-site or within the
      nearby vicinity, and because of the hyper-specific application, the
      software solution must allow for tailor-made flexibility.
    id: applications
    imageAlign: center
  - content: >-
      # Conclusion


      The immensity of data collected by sensors, and the immediate need to
      process that data to send back decisions, requires data processing speed
      and security that cannot be achieved in remote data processing centers or
      the cloud. This need for immense processing capability, as well as having
      the processing unit in closer physical vicinity to the sensors, provides
      the impetus for edge supercomputing. The dependence on algorithms and deep
      learning via CNN's and other high-performance algorithms to not only
      process visual stimuli, but to learn from it, requires an adaptable and
      malleable software solution conjoined with the processor technology that
      enables it. Quadric's team has designed a purpose-built edge supercomputer
      specifically to fill this void. With Quadric’s technology we are enabling
      the future of algorithms to be deployed today.
    id: conclusion
    imageAlign: center
---

